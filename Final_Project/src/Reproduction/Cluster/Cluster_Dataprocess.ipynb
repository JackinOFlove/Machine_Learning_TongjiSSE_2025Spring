{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('StrokeTest.csv')\n",
    "train_df = pd.read_csv('StrokeTrain.csv')\n",
    "body_pred_df = pd.read_csv('Stroke_Body_Pred.csv')\n",
    "\n",
    "# 创建一个字典用于查找 body_pred 对应的 index\n",
    "body_pred_to_index = body_pred_df.set_index('body_pred')['index'].to_dict()\n",
    "\n",
    "# 定义一个函数来查找 index\n",
    "def find_index(row):\n",
    "    return body_pred_to_index.get(row['k'], None)\n",
    "\n",
    "# 在 test 和 train 数据集中添加 index 列\n",
    "test_df['index'] = test_df.apply(find_index, axis=1)\n",
    "train_df['index'] = train_df.apply(find_index, axis=1)\n",
    "\n",
    "test_df.to_csv('StrokeTestIndex.csv', index=False)\n",
    "train_df.to_csv('StrokeTrainIndex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此处检查一下，是否存在 k 值不为 '1/2transfer3' 且 index 为 null 的行\n",
    "test_index_df = pd.read_csv('StrokeTestIndex.csv')\n",
    "train_index_df = pd.read_csv('StrokeTrainIndex.csv')\n",
    "\n",
    "# 筛选出 k 值不为 '1/2transfer3' 且 index 为 null 的行\n",
    "test_null_rows = test_index_df[(test_index_df['k'] != 'Middle_to_Sever') & (test_index_df['index'].isnull())]\n",
    "train_null_rows = train_index_df[(train_index_df['k'] != 'Middle_to_Sever') & (train_index_df['index'].isnull())]\n",
    "\n",
    "print(f\"Test file null rows count: {len(test_null_rows)}\")\n",
    "print(f\"Train file null rows count: {len(train_null_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 定义一个非常大的数，如果一个谓词对应的事件没有发生，则用一个很大的数来表示\n",
    "large_number = 1e10\n",
    "\n",
    "def process_dataframe(file_path, output_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    result = []\n",
    "    group = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['k'] == 'Middle_to_Sever':\n",
    "            # 处理当前组\n",
    "            if group:\n",
    "                group_id = group[0]['id']\n",
    "                # 初始化 body_predicates_time 数组\n",
    "                body_predicates_time = [large_number] * 48\n",
    "                # 填充 body_predicates_time 数组\n",
    "                for item in group:\n",
    "                    index = int(item['index'])\n",
    "                    body_predicates_time[index] = item['t']\n",
    "                # If body_predicates_time is all large_number, skip this group\n",
    "                if all(time == large_number for time in body_predicates_time):\n",
    "                    continue\n",
    "                # 获取 head_predicate_time\n",
    "                head_predicate_time = [row['t']]\n",
    "                # 添加到结果\n",
    "                result.append({\n",
    "                    'id': group_id,\n",
    "                    'body_predicates_time': body_predicates_time,\n",
    "                    'head_predicate_time': head_predicate_time\n",
    "                })\n",
    "            group = []\n",
    "        else:\n",
    "            group.append(row)\n",
    "    \n",
    "    np.save(output_path, result)\n",
    "    # 输出分组数\n",
    "    print(f\"{file_path} 数据集总共有 {len(result)} 组\")\n",
    "    # 打印前两个结果\n",
    "    print(f\"前两个结果: {result[:2]}\")\n",
    "\n",
    "# 处理测试集和训练集\n",
    "process_dataframe('StrokeTestIndex.csv', 'StrokeTestData.npy')\n",
    "process_dataframe('StrokeTrainIndex.csv', 'StrokeTrainData.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载 .npy 文件\n",
    "train_data = np.load('StrokeTrainData.npy', allow_pickle=True)\n",
    "test_data = np.load('StrokeTestData.npy', allow_pickle=True)\n",
    "\n",
    "def filter_data(data):\n",
    "    filtered_data = []\n",
    "    for group in data:\n",
    "        # 假设每组数据是一个字典，包含 'id', 'body_predicates_time', 'head_predicate_time'\n",
    "        body_predicates_time = group['body_predicates_time']\n",
    "        head_predicate_time = float(group['head_predicate_time'][0])  # 将 head_predicate_time 转换为数字\n",
    "        \n",
    "        # 找到 body_predicates_time 中的最大值，且不等于 10000000000.0\n",
    "        max_body_time = max(float(time) for time in body_predicates_time if float(time) != 10000000000.0)  # 将 body_predicates_time 中的值转换为数字\n",
    "        \n",
    "        # 检查条件\n",
    "        if max_body_time + 24 >= head_predicate_time:\n",
    "            filtered_data.append(group)\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# 过滤数据\n",
    "filtered_train_data = filter_data(train_data)\n",
    "filtered_test_data = filter_data(test_data)\n",
    "\n",
    "# 保存过滤后的数据\n",
    "np.save('StrokeTrain.npy', filtered_train_data)\n",
    "np.save('StrokeTest.npy', filtered_test_data)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"StrokeTrain.npy 中的组数: {len(filtered_train_data)}\")\n",
    "print(f\"StrokeTest.npy 中的组数: {len(filtered_test_data)}\")\n",
    "\n",
    "# 打印前两个组\n",
    "print(\"StrokeTrain.npy 前两个组:\", filtered_train_data[:2])\n",
    "print(\"StrokeTest.npy 前两个组:\", filtered_test_data[:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
